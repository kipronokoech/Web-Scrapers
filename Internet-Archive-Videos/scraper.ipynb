{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define the URL\n",
    "\n",
    "url=\"https://archive.org/details/opensource_movies\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse HTML code for the entire site\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "#print(soup.prettify()) # print the parsed data of html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Actual Scrapping of one movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "/Damas_BB_28F8B535_D\n",
      "1.4M\n",
      "1\n",
      "May 21, 2013\n"
     ]
    }
   ],
   "source": [
    "movies_collection = soup.find(\"div\", attrs={\"id\": \"ikind--downloads\"})\n",
    "\n",
    "# Scrape one movie\n",
    "\n",
    "aMovie = movies_collection.find_all(\"div\", attrs={\"class\": \"item-ia\"})\n",
    "first = aMovie[17]\n",
    "#print(first.prettify())\n",
    "#getting the title of the movie\n",
    "title = (first.find(\"div\",attrs={\"class\":\"ttl\"})).text\n",
    "title = title.strip()\n",
    "# Getting the views count of the movie\n",
    "views = first.find_all(\"h6\",attrs={\"class\":\"stat\"})[0].nobr.text\n",
    "# Stars count\n",
    "stars = first.find_all(\"h6\",attrs={\"class\":\"stat\"})[1].text\n",
    "# example output of above line if \"favorite            12 \"\n",
    "# below line will extract the number from the string above\n",
    "stars = re.findall(\"\\d+\",stars)[0]\n",
    "\n",
    "comments =  first.find_all(\"h6\",attrs={\"class\":\"stat\"})[2].text\n",
    "comments = re.findall(\"\\d+\",comments)[0]\n",
    "\n",
    "posted_on = ((first.find_all(\"div\",attrs={\"class\":\"hidden-tiles\"}))[1]).nobr.text\n",
    "print(stars)\n",
    "print(title)\n",
    "print(views)\n",
    "print(comments)\n",
    "print(posted_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Writing one movie into .txt file as #-separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now write one movie details into text file\n",
    "# JUst like we have comma for CSV we will use # as the separator\n",
    "# Lets write the titles first\n",
    "with open(\"./output/oneMovie.txt\",\"w+\") as fp:\n",
    "    #lets write the titles first\n",
    "    fp.write(\"Title#Views#Stars#Comments#Posted_on\\n\")\n",
    "\n",
    "\n",
    "# Lets now write details into the\n",
    "with open(\"./output/oneMovie.txt\",\"a+\") as fp:\n",
    "    #lets write the details\n",
    "    one_movie_details = \"#\".join((title, views, stars, comments, posted_on))\n",
    "    fp.write(one_movie_details+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website we are scrapping contain multiple pages - you should be able to notice the change in URL as you scroll. The URLs for different pages appear as follows:\n",
    " - Page 1 : https://archive.org/details/opensource_movies or https://archive.org/details/opensource_movies?&sort=-downloads&page=1\n",
    " - Page 2  : https://archive.org/details/opensource_movies?&sort=-downloads&page=2\n",
    " - Page 3 : https://archive.org/details/opensource_movies?&sort=-downloads&page=3\n",
    " - etc\n",
    " \n",
    "I trust you can see the pattern. What changes is the number at the end and therefore we can loop through the pages easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets now scrape the first 10 pages (all the movies in every page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets open file to write to\n",
    "f = open(\"./output/movies.txt\",\"a+\")\n",
    "# Write the titles\n",
    "f.write(\"Title#=View#=Stars#=Comments#=Posted_on\\n\")\n",
    "#initialize paging\n",
    "page_no = 1\n",
    "while page_no <=10:\n",
    "    #Lets define the URL - putting in mind the web pagging explained above\n",
    "    url=\"https://archive.org/details/opensource_movies?&sort=-downloads&page={}\".format(page_no)\n",
    "    # Make a GET request to fetch the raw HTML content\n",
    "    html_content = requests.get(url).text\n",
    "    # Parse HTML code for the entire site\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    #print(soup.prettify()) # print the parsed data of html\n",
    "    # Movie section\n",
    "    movies_collection = soup.find(\"div\", attrs={\"id\": \"ikind--downloads\"})\n",
    "    # find all the movies in page one\n",
    "    aMovie = movies_collection.find_all(\"div\", attrs={\"class\": \"item-ia\"})\n",
    "\n",
    "    for index in range(1,len(aMovie)): #note that movies starts from index 1\n",
    "        another = aMovie[index]\n",
    "        #print(another.prettify())\n",
    "        #getting the title of the movie\n",
    "        title = (another.find(\"div\",attrs={\"class\":\"ttl\"})).text\n",
    "        title = title.strip()\n",
    "        # Getting the views count of the movie\n",
    "        views = another.find_all(\"h6\",attrs={\"class\":\"stat\"})[0].nobr.text\n",
    "        # Stars count\n",
    "        stars = another.find_all(\"h6\",attrs={\"class\":\"stat\"})[1].text\n",
    "        # example output of above line if \"favorite            12 \"\n",
    "        # below line will extract the number from the string above\n",
    "        stars = re.findall(\"\\d+\",stars)[0]\n",
    "        #comments\n",
    "        comments =  another.find_all(\"h6\",attrs={\"class\":\"stat\"})[2].text\n",
    "        comments = re.findall(\"\\d+\",comments)[0]\n",
    "\n",
    "        posted_on = ((another.find_all(\"div\",attrs={\"class\":\"hidden-tiles\"}))[1]).nobr.text\n",
    "        one_movie_details = \"#=\".join((title, views, stars, comments, posted_on))\n",
    "        f.write(one_movie_details+\"\\n\")\n",
    "    page_no = page_no + 1\n",
    "#close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading .txt file into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>View</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Posted_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Namaz nas覺l k覺l覺n覺r?</td>\n",
       "      <td>3M</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 26, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cCloud TV v0.6 Rise</td>\n",
       "      <td>2.5M</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Nov 26, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O Shahade Amira Imarata Kavkaz Dokku Abu Usmana</td>\n",
       "      <td>2.3M</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Jul 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>israelbicepilp</td>\n",
       "      <td>2.1M</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>May 28, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medical Videos - 05 Normal Spontsneous vaginal...</td>\n",
       "      <td>1.9M</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>Oct 23, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>El Senor Es Bueno Gracias Por Todooos</td>\n",
       "      <td>1.8M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Feb 5, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dokku_obrash</td>\n",
       "      <td>1.8M</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Oct 30, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unlimited_earning_trick_on_mobile_premier_leag...</td>\n",
       "      <td>1.8M</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan 29, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wanyed Mbuapa</td>\n",
       "      <td>1.7M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>May 9, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>His new job ( Charles Chaplin-1915)</td>\n",
       "      <td>1.6M</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>Aug 2, 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  View Stars Comments  \\\n",
       "0                               Namaz nas覺l k覺l覺n覺r?    3M     3        0   \n",
       "1                                cCloud TV v0.6 Rise  2.5M    12        1   \n",
       "2    O Shahade Amira Imarata Kavkaz Dokku Abu Usmana  2.3M    11        2   \n",
       "3                                     israelbicepilp  2.1M    25        9   \n",
       "4  Medical Videos - 05 Normal Spontsneous vaginal...  1.9M    67       10   \n",
       "5              El Senor Es Bueno Gracias Por Todooos  1.8M     0        0   \n",
       "6                                       Dokku_obrash  1.8M     2        0   \n",
       "7  unlimited_earning_trick_on_mobile_premier_leag...  1.8M     0        1   \n",
       "8                                      Wanyed Mbuapa  1.7M     1        1   \n",
       "9                His new job ( Charles Chaplin-1915)  1.6M    21        3   \n",
       "\n",
       "      Posted_on  \n",
       "0  Dec 26, 2019  \n",
       "1  Nov 26, 2015  \n",
       "2  Jul 20, 2014  \n",
       "3  May 28, 2011  \n",
       "4  Oct 23, 2010  \n",
       "5   Feb 5, 2020  \n",
       "6  Oct 30, 2014  \n",
       "7  Jan 29, 2020  \n",
       "8   May 9, 2018  \n",
       "9   Aug 2, 2012  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"./output/movies.txt\",sep=\"#=\",engine=\"python\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
